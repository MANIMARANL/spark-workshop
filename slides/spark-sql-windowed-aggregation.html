<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Apache Spark™ Workshop | Spark SQL | Windowed Aggregation</title>

    <meta name="description" content="Apache Spark™ Workshop | Spark SQL | Windowed Aggregation">
    <meta name="author" content="Jacek Laskowski">

    <link rel="stylesheet" href="reveal.js/css/reveal.css">
    <link rel="stylesheet" href="reveal.js/css/theme/beige.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

    <!-- Jacek: custom formatting -->
    <link rel="stylesheet" href="revealjs-css/jacek.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement('link');
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match(/print-pdf/gi) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
      document.getElementsByTagName('head')[0].appendChild(link);
    </script>
  </head>

  <body>
    <div class="reveal">

      <div class="footer">
        <footer style="font-size: small;">
          &copy; <a href="https://medium.com/@jaceklaskowski">Jacek Laskowski</a> 2019 / <a href="https://twitter.com/jaceklaskowski">@JacekLaskowski</a>
          / jacek@japila.pl
        </footer>
      </div>

      <div class="slides">

        <section class="intro" data-transition="zoom" id="home">
          <p>
            <img width="12%" style="background:none; border:none; box-shadow:none;" data-src="images/spark-logo.png">
            <img width="6%" src="images/jacek_laskowski_20141201_512px.png" style="border: 0">
          </p>
          <h1 style="font-size: 3.47em;">Windowed Aggregation</h1>
          <h3>Apache Spark 2.4.4 / Spark SQL</h3>

          <br />
          <br />
          <hr />
          <h4 style="font-size: smaller;">
            <a href="https://twitter.com/jaceklaskowski">@jaceklaskowski</a> / <a href="https://stackoverflow.com/users/1305344/jacek-laskowski">StackOverflow</a> / <a href="https://github.com/jaceklaskowski">GitHub</a>
            <br>
            The "Internals" Books: <a href="https://bit.ly/apache-spark-internals">Apache Spark</a> / <a href="https://bit.ly/spark-sql-internals">Spark SQL</a> / <a href="https://bit.ly/spark-structured-streaming">Spark Structured Streaming</a>
          </h4>
        </section>

        <section id="agenda" data-markdown>
          <textarea data-template>
            ## Agenda

            1. [Window Aggregate Functions](#/window-aggregate-functions)
            1. [Window Functions](#/window-functions)
            1. [Window Specification](#/window-specification)
            1. [over Column Operator](#/over-column-operator)
            1. [Demo](#/demo)
          </textarea>
        </section>

        <section id="window-aggregate-functions" data-markdown style="font-size: 90%">
          <textarea data-template>
            ## Window Aggregate Functions

            1. **Window Aggregate Functions** are standard functions that perform calculations over a group of records called **window**
            1. Window defines a logical group of rows that are in some relation to the current record
            1. Generate a value for **every row**
              * Unlike basic aggregations that generate **at most** the number of input rows
            1. Switch to [The Internals of Spark SQL](https://bit.ly/spark-sql-internals)
              * [Window Aggregation Functions](https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-functions-windows.html)
          </textarea>
        </section>
        <section id="window-functions" data-markdown>
          <textarea data-template>
            ## Window Functions

            1. **Aggregate functions**
              * sum, avg, min, max, count, etc.
              * User-Defined Aggregate Functions (UDAFs)
            1. **Ranking functions**
              * rank, dense_rank, percent_rank
              * ntile
              * row_number
            1. **Analytic functions**
              * cume_dist, lag, lead
          </textarea>
        </section>

        <section>
          <section id="window-specification" data-markdown style="font-size: 75%">
            <textarea data-template>
              ## Window Specification / WindowSpec

              1. **Window Specification** defines a **window** (logical view) that includes the rows that are in relation to the current row (for every row)
              1. (Logically) **partitions** dataset into groups
                * **partitionBy**
              1. May define **frame boundary**
                * **rangeBetween**, **rowsBetween**
              1. May define **ordering**
                * **orderBy**
                * Uses an unbounded window frame (rowFrame, unboundedPreceding, unboundedFollowing) for undefined ordering
                * Uses a growing window frame (rangeFrame, unboundedPreceding, currentRow) with ordering defined
            </textarea>
          </section>
          <section id="windowspec" data-markdown>
            <textarea data-template>
              ## Window Factory Object

              1. Use **Window** factory object to create **WindowSpec**
              <pre style="margin-left: 0px;"><code style="width: 900px;" class="lang-scala hljs">import org.apache.spark.sql.expressions.Window
                val departmentById = Window
                  .partitionBy("department")
                  .orderBy("id")
                  .rangeBetween(Window.unboundedPreceding, Window.unboundedFollowing)
              </code></pre>
            </textarea>
          </section>
        </section>

        <section id="over-column-operator" data-markdown>
          <textarea data-template>
            <!-- .slide: style="font-size: 90%" -->
            ## over Column Operator

            1. **over** column operator defines a **windowing column** (aka **analytic clause**)
            1. Applies window function over window
            ```scala
              val overUnspecifiedFrame = sum('someColumn).over()
              val overRange = rank over someWindow
            ```
            1. Use with **withColumn** or **select** operators
            ```scala
              numbers.withColumn("max", max("num") over dividedBy2)
            ```
            1. Switch to [The Internals of Spark SQL](https://bit.ly/spark-sql-internals)
              * [Defining Windowing Column (Analytic Clause) &mdash; over Operator](https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-Column.html#over)
          </textarea>
        </section>

        <section id="demo" data-markdown>
          <textarea data-template>
            <!-- .slide: style="font-size: 90%" -->
            ## Demo: Finding Most Populated Cities Per Country

            1. [Exercise: Finding Most Populated Cities Per Country](https://jaceklaskowski.github.io/spark-workshop/exercises/sql/Finding-Most-Populated-Cities-Per-Country.html) using windowed aggregation
            1. Compare the execution plan to a structured query with groupBy and join operators (web UI)
              * Disable [broadcast join](https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-joins-broadcast.html) using spark.sql.autoBroadcastJoinThreshold property
          </textarea>
        </section>

        <section id="recap" data-markdown>
          <textarea data-template>
            ## Recap

            1. [Window Aggregate Functions](#/window-aggregate-functions)
            1. [Window Functions](#/window-functions)
            1. [Window Specification](#/window-specification)
            1. [over Column Operator](#/over-column-operator)
            1. [Demo](#/demo)
          </textarea>
        </section>

        <section style="text-align: left" data-markdown id="questions">
          <textarea data-template>
            # Questions?

            * Read [The Internals of Apache Spark](https://bit.ly/apache-spark-internals)
            * Read [The Internals of Spark SQL](https://bit.ly/spark-sql-internals)
            * Read [The Internals of Spark Structured Streaming](https://bit.ly/spark-structured-streaming)
            * Follow [@jaceklaskowski](https://twitter.com/jaceklaskowski) on twitter
            * Upvote [my questions and answers on StackOverflow](http://stackoverflow.com/users/1305344/jacek-laskowski)
          </textarea>
        </section>

      </div>
    </div>

    <script src="reveal.js/lib/js/head.min.js"></script>
    <script src="reveal.js/js/reveal.js"></script>

    <script>
      // More info about config & dependencies:
      // - https://github.com/hakimel/reveal.js#configuration
      // - https://github.com/hakimel/reveal.js#dependencies
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        slideNumber: true,

        transition: 'slide', // none/fade/slide/convex/concave/zoom

        menu: {
          markers: true,
          openSlideNumber: true
        },
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function () { return !document.body.classList; } },
          { src: 'reveal.js/plugin/markdown/marked.js' },
          { src: 'reveal.js/plugin/markdown/markdown.js' },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true },
          { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad(); } }
        ]
      });
    </script>
    <script>
      (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
          m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
      })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

      ga('create', 'UA-45999426-3', 'auto');
      ga('send', 'pageview');

    </script>
  </body>
</html>
